{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import dependencies¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 22:39:06.324607\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "currentDT = datetime.datetime.now()\n",
    "print (str(currentDT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create PyTorch data generators¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def to_device(x, y):\n",
    "    return x.to(device), y.to(device, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloader parameters\n",
    "batch_size = 64\n",
    "num_workers_train = 2\n",
    "num_workers_validation = 4\n",
    "num_workers_test = 4\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "normalize = transforms.Normalize(mean=[0.5],\n",
    "                                 std=[0.5])\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.Grayscale(1),\n",
    "        transforms.RandomApply([\n",
    "            transforms.RandomAffine(0, translate=(0.2, 0.2), resample=Image.BICUBIC),\n",
    "            transforms.RandomAffine(0, shear=20, resample=Image.BICUBIC),\n",
    "            transforms.RandomAffine(0, scale=(0.8, 1.2), resample=Image.BICUBIC)\n",
    "        ]), \n",
    "#        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "])\n",
    "\n",
    "data_transform_test = transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.Grayscale(1),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "])\n",
    "\n",
    "image_datasets = {\n",
    "    'train':\n",
    "        datasets.ImageFolder('./source_data_2/train/', data_transform),\n",
    "    'validation': \n",
    "        datasets.ImageFolder('./source_data_2/valid/', data_transform),\n",
    "    'test': \n",
    "        datasets.ImageFolder('./source_data_2/test/', data_transform_test)\n",
    "}\n",
    "\n",
    "a = torch.utils.data.DataLoader(image_datasets['train'],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True, num_workers=num_workers_train)\n",
    "b = torch.utils.data.DataLoader(image_datasets['validation'],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False, num_workers=num_workers_validation)\n",
    "c = torch.utils.data.DataLoader(image_datasets['test'],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False, num_workers=num_workers_test)\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "    WrappedDataLoader(a, to_device),\n",
    "    'validation':\n",
    "    WrappedDataLoader(b, to_device),\n",
    "    'test':\n",
    "    WrappedDataLoader(c, to_device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate sample weights\n",
    "#train_size = datasize = len(image_datasets['train'])\n",
    "train_size = 43 * 15000\n",
    "\n",
    "def get_weighted_loader():\n",
    "    class_sample_count = pd.read_csv('sign_count.csv')['count'].to_numpy()\n",
    "    class_weights = 1 / class_sample_count\n",
    "    class_id=0\n",
    "    sample_weights = list()\n",
    "    for class_weight in class_weights:\n",
    "        sample_weights += ([class_weight] * class_sample_count[class_id])\n",
    "        class_id += 1\n",
    "\n",
    "    #replace train dataset\n",
    "    samp = sampler.WeightedRandomSampler(sample_weights, train_size)\n",
    "    a = torch.utils.data.DataLoader(image_datasets['train'],\n",
    "                                    batch_size=batch_size,\n",
    "                                    num_workers=num_workers_train, sampler=samp)\n",
    "    return WrappedDataLoader(a, to_device)\n",
    "\n",
    "dataloaders['train'] = get_weighted_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify weights\n",
    "def vis_weighted_sign_count():\n",
    "    balanced_y_train = torch.LongTensor([]).to(device)\n",
    "    i = 0\n",
    "    progress_bar_weights = tqdm(range(int(train_size/batch_size)), desc='Checking weights: ')\n",
    "    with torch.no_grad():\n",
    "        for _, y in dataloaders['train']:\n",
    "            i += 1\n",
    "            balanced_y_train = torch.cat((balanced_y_train, y))\n",
    "            progress_bar_weights.update()\n",
    "\n",
    "    print('iterations: {}'.format(i))\n",
    "    print('images: {}'.format(len(balanced_y_train)))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(range(43), np.bincount(balanced_y_train.cpu().numpy()), 0.5)\n",
    "    ax.set_xlabel('Signs')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('The count of each sign')\n",
    "    plt.show()\n",
    "\n",
    "#vis_weighted_sign_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.resnet50(pretrained=True).to(device)\n",
    "#    \n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False   \n",
    "    \n",
    "#model.fc = nn.Sequential(\n",
    "#               nn.Linear(2048, 128),\n",
    "#               nn.ReLU(inplace=True),\n",
    "#               nn.Linear(128, 43)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Stn, self).__init__()\n",
    "        # Spatial transformer localization-network\n",
    "        self.loc_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 50, 7),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(50, 100, 5),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(100 * 4 * 4, 100),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(100, 3 * 2)\n",
    "        )\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xs = self.loc_net(x)\n",
    "        xs = xs.view(-1, 100 * 4 * 4)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self, gray=False):\n",
    "        super(BaselineNet, self).__init__()\n",
    "        #input_chan = 1 if gray else 3\n",
    "        self.stn = Stn()\n",
    "        self.conv1 = nn.Conv2d(1, 100, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(100)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(100, 150, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(250)\n",
    "        self.fc1 = nn.Linear(250 * 3 * 3, 350)\n",
    "        self.fc1_bn = nn.BatchNorm1d(350)\n",
    "        self.fc2 = nn.Linear(350, 43)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stn(x)\n",
    "        x = self.pool(F.elu(self.conv1(x)))\n",
    "        x = self.dropout(self.conv1_bn(x))\n",
    "        x = self.pool(F.elu(self.conv2(x)))\n",
    "        x = self.dropout(self.conv2_bn(x))\n",
    "        x = self.pool(F.elu(self.conv3(x)))\n",
    "        x = self.dropout(self.conv3_bn(x))\n",
    "        x = x.view(-1, 250 * 3 * 3)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.dropout(self.fc1_bn(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = BaselineNet(gray=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies weights to module\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model\n",
    "    if classname.find('Linear') != -1:\n",
    "        # get number of inputs\n",
    "        n = m.in_features\n",
    "        y = (1.0/np.sqrt(n))\n",
    "        m.weight.data.normal_(0, y)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "#model.apply(weights_init_normal)\n",
    "\n",
    "# Stn is already initalized, so only apply weithgs to our part of the model \n",
    "weights_init_normal(model.fc1)\n",
    "weights_init_normal(model.fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.start')\n",
    "#model.load_state_dict(torch.load('model.start'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.resnet18(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False   \n",
    "#model.fc = nn.Linear(512, 43).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaselineNet(\n",
      "  (stn): Stn(\n",
      "    (loc_net): Sequential(\n",
      "      (0): Conv2d(1, 50, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): Conv2d(50, 100, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): ELU(alpha=1.0)\n",
      "    )\n",
      "    (fc_loc): Sequential(\n",
      "      (0): Linear(in_features=1600, out_features=100, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=100, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1): Conv2d(1, 100, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(100, 150, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2_bn): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(150, 250, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv3_bn): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=2250, out_features=350, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(350, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=350, out_features=43, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'validation']:\n",
    "            datasize = len(image_datasets[phase])\n",
    "            if phase == 'train':\n",
    "                datasize = train_size\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            train_loss = 0.0\n",
    "            i = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.detach() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)                                \n",
    "\n",
    "                epoch_loss = running_loss / datasize\n",
    "                epoch_acc = running_corrects.float() / datasize\n",
    "                train_loss += loss.item()\n",
    "                if i % 500 == 499:\n",
    "                    print('phase: {}, batch: {}, loss: {:.4f}, train_loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                                        i+1,\n",
    "                                                                        epoch_loss.item(),\n",
    "                                                                        train_loss / 500,\n",
    "                                                                        epoch_acc.item()))\n",
    "                    train_loss = 0.0\n",
    "                i += 1\n",
    "\n",
    "\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss.item(),\n",
    "                                                        epoch_acc.item()))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, x, y, opt=None):\n",
    "    loss = loss_func(model(x), y)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_batch(model, loss_func, x, y):\n",
    "    output = model(x)\n",
    "    loss = loss_func(output, y)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    correct = pred == y.view(*pred.shape)\n",
    "    \n",
    "    return loss.item(), torch.sum(correct).item(), len(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_func, dl):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses, corrects, nums = zip(*[valid_batch(model, loss_func, x, y) for x, y in dl])\n",
    "        test_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        test_accuracy = np.sum(corrects) / np.sum(nums) * 100\n",
    "        \n",
    "    print(f\"Test loss: {test_loss:.6f}\\t\"\n",
    "          f\"Test accruacy: {test_accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2764: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: train, batch: 500, loss: 0.2041, train_loss: 4.1137, acc: 0.0013\n",
      "phase: train, batch: 1000, loss: 0.4024, train_loss: 3.9973, acc: 0.0027\n",
      "phase: train, batch: 1500, loss: 0.5961, train_loss: 3.9044, acc: 0.0039\n",
      "phase: train, batch: 2000, loss: 0.7872, train_loss: 3.8520, acc: 0.0050\n",
      "phase: train, batch: 2500, loss: 0.9772, train_loss: 3.8287, acc: 0.0061\n",
      "phase: train, batch: 3000, loss: 1.1666, train_loss: 3.8173, acc: 0.0073\n",
      "phase: train, batch: 3500, loss: 1.3555, train_loss: 3.8094, acc: 0.0083\n",
      "phase: train, batch: 4000, loss: 1.5441, train_loss: 3.7995, acc: 0.0095\n",
      "phase: train, batch: 4500, loss: 1.7324, train_loss: 3.7968, acc: 0.0107\n",
      "phase: train, batch: 5000, loss: 1.9205, train_loss: 3.7902, acc: 0.0118\n",
      "phase: train, batch: 5500, loss: 2.1083, train_loss: 3.7851, acc: 0.0129\n",
      "phase: train, batch: 6000, loss: 2.2958, train_loss: 3.7805, acc: 0.0141\n",
      "phase: train, batch: 6500, loss: 2.4831, train_loss: 3.7747, acc: 0.0152\n",
      "phase: train, batch: 7000, loss: 2.6702, train_loss: 3.7716, acc: 0.0164\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-f413d8d4978b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model = train_model(model, criterion, optimizer, num_epochs=1)\n",
    "evaluate(model, criterion, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'model.pre-trained_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('model.pre-trained_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2764: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: train, batch: 500, loss: 0.1870, train_loss: 3.7685, acc: 0.0012\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-f413d8d4978b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#decrease lr and train more \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "model = train_model(model, criterion, optimizer, num_epochs=6)\n",
    "evaluate(model, criterion, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'model.pre-trained_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2764: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.764059\tTest accruacy: 5.701%\n",
      "CPU times: user 1.39 s, sys: 266 ms, total: 1.66 s\n",
      "Wall time: 2.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate(model, criterion, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2764: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_image_np(inp):\n",
    "    \"\"\"Convert a Tensor to numpy image.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    mean = np.array([0.5])\n",
    "    std = np.array([0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "def visualize_stn():\n",
    "    with torch.no_grad():\n",
    "        data = next(iter(dataloaders['train']))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_tensor = model.stn(data).cpu()\n",
    "\n",
    "        input_grid = convert_image_np(make_grid(input_tensor))\n",
    "        transformed_grid = convert_image_np(make_grid(transformed_tensor))\n",
    "\n",
    "        # Plot the results side-by-side\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        fig.set_size_inches((16, 16))\n",
    "        ax[0].imshow(input_grid)\n",
    "        ax[0].set_title('Dataset Images')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(transformed_grid)\n",
    "        ax[1].set_title('Transformed Images')\n",
    "        ax[1].axis('off')\n",
    "        \n",
    "visualize_stn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#unfreeze the whole model and train for two more epochs\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = True \n",
    "#model = train_model(model, criterion, optimizer, num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save and load the model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.resnet50(pretrained=False).to(device)\n",
    "#model.fc = nn.Sequential(\n",
    "#               nn.Linear(2048, 128),\n",
    "#               nn.ReLU(inplace=True),\n",
    "#               nn.Linear(128, 2)).to(device)\n",
    "#model.load_state_dict(torch.load('weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.resnet18(pretrained=False).to(device)\n",
    "#model.fc = nn.Linear(512, 43).to(device)\n",
    "#model.load_state_dict(torch.load('weights.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Make predictions on sample test images¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_img_paths = [\"./source_data_2/test/00/00243.ppm\",\n",
    "                        \"./source_data_2/test/01/00001.ppm\",\n",
    "                        \"./source_data_2/test/02/00034.ppm\"]\n",
    "#validation_img_paths = [\"./source_data_2/train/35/hflip_hflip_00039_00010.ppm\",\n",
    "#                        \"./source_data_2/train/35/hflip_hflip_00039_00021.ppm\",\n",
    "#                        \"./source_data_2/train/35/hflip_hflip_00039_00029.ppm\"]\n",
    "img_list = [Image.open(img_path) for img_path in validation_img_paths]\n",
    "validation_classes = [0, 1, 2]\n",
    "#validation_classes = [35, 35, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_batch = torch.stack([data_transform(img).to(device)\n",
    "                                for img in img_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits_tensor = model(validation_batch)\n",
    "pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_probs=np.random.random_sample((3, 43))\n",
    "\n",
    "fig, axs = plt.subplots(1, len(img_list), figsize=(10, 3))\n",
    "for i, img in enumerate(img_list):\n",
    "    ax = axs[i]\n",
    "    ax.axis('off')\n",
    "    maxConfidenceValue = np.amax(pred_probs[i,:])\n",
    "    maxConfidenceClass = np.where(pred_probs[i,:] == maxConfidenceValue)[0][0]\n",
    "    color = 'green'\n",
    "    if maxConfidenceClass != validation_classes[i]:\n",
    "        color = 'red'\n",
    "    ax.set_title(\"GT: {}, Top: {} ({:.2f}%)\".format(validation_classes[i], maxConfidenceClass, maxConfidenceValue*100), color=color)\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDT = datetime.datetime.now()\n",
    "print (str(currentDT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
