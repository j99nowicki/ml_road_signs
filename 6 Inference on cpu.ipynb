{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Load and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-04 16:38:29.906753\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "currentDT = datetime.datetime.now()\n",
    "print (str(currentDT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create PyTorch data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def to_device(x, y):\n",
    "    return x.to(device), y.to(device, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloader parameters\n",
    "batch_size = 64\n",
    "num_workers_train = 2\n",
    "num_workers_validation = 4\n",
    "num_workers_test = 4\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "normalize = transforms.Normalize(mean=[0.5],\n",
    "                                 std=[0.5])\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.Grayscale(1),\n",
    "        transforms.RandomApply([\n",
    "            transforms.RandomAffine(0, translate=(0.2, 0.2), resample=Image.BICUBIC),\n",
    "            transforms.RandomAffine(0, shear=20, resample=Image.BICUBIC),\n",
    "            transforms.RandomAffine(0, scale=(0.8, 1.2), resample=Image.BICUBIC)\n",
    "        ]), \n",
    "#        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "])\n",
    "\n",
    "data_transform_test = transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.Grayscale(1),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "])\n",
    "\n",
    "image_datasets = {\n",
    "    'train':\n",
    "        datasets.ImageFolder('./source_data_2/train/', data_transform),\n",
    "    'validation': \n",
    "        datasets.ImageFolder('./source_data_2/valid/', data_transform),\n",
    "    'test': \n",
    "        datasets.ImageFolder('./source_data_2/test/', data_transform_test)\n",
    "}\n",
    "\n",
    "a = torch.utils.data.DataLoader(image_datasets['train'],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True, num_workers=num_workers_train)\n",
    "b = torch.utils.data.DataLoader(image_datasets['validation'],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False, num_workers=num_workers_validation)\n",
    "c = torch.utils.data.DataLoader(image_datasets['test'],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False, num_workers=num_workers_test)\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "    WrappedDataLoader(a, to_device),\n",
    "    'validation':\n",
    "    WrappedDataLoader(b, to_device),\n",
    "    'test':\n",
    "    WrappedDataLoader(c, to_device)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.resnet50(pretrained=True).to(device)\n",
    "#    \n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False   \n",
    "    \n",
    "#model.fc = nn.Sequential(\n",
    "#               nn.Linear(2048, 128),\n",
    "#               nn.ReLU(inplace=True),\n",
    "#               nn.Linear(128, 43)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Stn, self).__init__()\n",
    "        # Spatial transformer localization-network\n",
    "        self.loc_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 50, 7),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(50, 100, 5),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(100 * 4 * 4, 100),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(100, 3 * 2)\n",
    "        )\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xs = self.loc_net(x)\n",
    "        xs = xs.view(-1, 100 * 4 * 4)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self, gray=False):\n",
    "        super(BaselineNet, self).__init__()\n",
    "        #input_chan = 1 if gray else 3\n",
    "        self.stn = Stn()\n",
    "        self.conv1 = nn.Conv2d(1, 100, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(100)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(100, 150, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(250)\n",
    "        self.fc1 = nn.Linear(250 * 3 * 3, 350)\n",
    "        self.fc1_bn = nn.BatchNorm1d(350)\n",
    "        self.fc2 = nn.Linear(350, 43)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stn(x)\n",
    "        x = self.pool(F.elu(self.conv1(x)))\n",
    "        x = self.dropout(self.conv1_bn(x))\n",
    "        x = self.pool(F.elu(self.conv2(x)))\n",
    "        x = self.dropout(self.conv2_bn(x))\n",
    "        x = self.pool(F.elu(self.conv3(x)))\n",
    "        x = self.dropout(self.conv3_bn(x))\n",
    "        x = x.view(-1, 250 * 3 * 3)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.dropout(self.fc1_bn(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = BaselineNet(gray=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaselineNet(\n",
      "  (stn): Stn(\n",
      "    (loc_net): Sequential(\n",
      "      (0): Conv2d(1, 50, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): Conv2d(50, 100, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): ELU(alpha=1.0)\n",
      "    )\n",
      "    (fc_loc): Sequential(\n",
      "      (0): Linear(in_features=1600, out_features=100, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=100, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1): Conv2d(1, 100, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(100, 150, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2_bn): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(150, 250, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv3_bn): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=2250, out_features=350, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(350, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=350, out_features=43, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, x, y, opt=None):\n",
    "    loss = loss_func(model(x), y)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_batch(model, loss_func, x, y):\n",
    "    output = model(x)\n",
    "    loss = loss_func(output, y)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    correct = pred == y.view(*pred.shape)\n",
    "    \n",
    "    return loss.item(), torch.sum(correct).item(), len(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_func, dl):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses, corrects, nums = zip(*[valid_batch(model, loss_func, x, y) for x, y in dl])\n",
    "        test_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        test_accuracy = np.sum(corrects) / np.sum(nums) * 100\n",
    "        \n",
    "    print(f\"Test loss: {test_loss:.6f}\\t\"\n",
    "          f\"Test accruacy: {test_accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pre-trained_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2764: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: train, batch: 500, loss: 0.1393, train_loss: 2.8079, acc: 0.0142\n",
      "phase: train, batch: 1000, loss: 0.1921, train_loss: 1.0635, acc: 0.0492\n",
      "phase: train, batch: 1500, loss: 0.2274, train_loss: 0.7123, acc: 0.0891\n",
      "phase: train, batch: 2000, loss: 0.2544, train_loss: 0.5434, acc: 0.1311\n",
      "phase: train, batch: 2500, loss: 0.2764, train_loss: 0.4446, acc: 0.1745\n",
      "phase: train, batch: 3000, loss: 0.2970, train_loss: 0.4142, acc: 0.2182\n",
      "phase: train, batch: 3500, loss: 0.3181, train_loss: 0.4249, acc: 0.2619\n",
      "phase: train, batch: 4000, loss: 0.3368, train_loss: 0.3778, acc: 0.3061\n",
      "phase: train, batch: 4500, loss: 0.3551, train_loss: 0.3699, acc: 0.3506\n",
      "phase: train, batch: 5000, loss: 0.3726, train_loss: 0.3527, acc: 0.3952\n",
      "phase: train, batch: 5500, loss: 0.3900, train_loss: 0.3489, acc: 0.4398\n",
      "phase: train, batch: 6000, loss: 0.4070, train_loss: 0.3438, acc: 0.4845\n",
      "phase: train, batch: 6500, loss: 0.4242, train_loss: 0.3470, acc: 0.5292\n",
      "phase: train, batch: 7000, loss: 0.4381, train_loss: 0.2803, acc: 0.5748\n",
      "phase: train, batch: 7500, loss: 0.4551, train_loss: 0.3423, acc: 0.6195\n",
      "phase: train, batch: 8000, loss: 0.4692, train_loss: 0.2845, acc: 0.6649\n",
      "phase: train, batch: 8500, loss: 0.4840, train_loss: 0.2981, acc: 0.7102\n",
      "phase: train, batch: 9000, loss: 0.5003, train_loss: 0.3291, acc: 0.7551\n",
      "phase: train, batch: 9500, loss: 0.5174, train_loss: 0.3444, acc: 0.7998\n",
      "phase: train, batch: 10000, loss: 0.5341, train_loss: 0.3363, acc: 0.8445\n",
      "train loss: 0.5361, acc: 0.8517\n",
      "validation loss: 0.1236, acc: 0.9674\n",
      "Test loss: 0.090452\tTest accruacy: 97.435%\n",
      "CPU times: user 3min 51s, sys: 32.5 s, total: 4min 23s\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate(model, criterion, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'model.pre-trained_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('model.pre-trained_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2764: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: train, batch: 500, loss: 0.0062, train_loss: 0.1252, acc: 0.0478\n",
      "phase: train, batch: 1000, loss: 0.0114, train_loss: 0.1054, acc: 0.0959\n",
      "phase: train, batch: 1500, loss: 0.0159, train_loss: 0.0897, acc: 0.1442\n",
      "phase: train, batch: 2000, loss: 0.0200, train_loss: 0.0831, acc: 0.1926\n",
      "phase: train, batch: 2500, loss: 0.0242, train_loss: 0.0853, acc: 0.2410\n",
      "phase: train, batch: 3000, loss: 0.0281, train_loss: 0.0775, acc: 0.2896\n",
      "phase: train, batch: 3500, loss: 0.0316, train_loss: 0.0716, acc: 0.3381\n",
      "phase: train, batch: 4000, loss: 0.0351, train_loss: 0.0695, acc: 0.3867\n",
      "phase: train, batch: 4500, loss: 0.0388, train_loss: 0.0743, acc: 0.4353\n",
      "phase: train, batch: 5000, loss: 0.0422, train_loss: 0.0680, acc: 0.4839\n",
      "phase: train, batch: 5500, loss: 0.0455, train_loss: 0.0677, acc: 0.5326\n",
      "phase: train, batch: 6000, loss: 0.0487, train_loss: 0.0650, acc: 0.5813\n",
      "phase: train, batch: 6500, loss: 0.0517, train_loss: 0.0596, acc: 0.6300\n",
      "phase: train, batch: 7000, loss: 0.0546, train_loss: 0.0596, acc: 0.6788\n",
      "phase: train, batch: 7500, loss: 0.0578, train_loss: 0.0641, acc: 0.7275\n",
      "phase: train, batch: 8000, loss: 0.0607, train_loss: 0.0588, acc: 0.7763\n",
      "phase: train, batch: 8500, loss: 0.0635, train_loss: 0.0548, acc: 0.8251\n",
      "phase: train, batch: 9000, loss: 0.0664, train_loss: 0.0590, acc: 0.8738\n",
      "phase: train, batch: 9500, loss: 0.0692, train_loss: 0.0565, acc: 0.9226\n",
      "phase: train, batch: 10000, loss: 0.0721, train_loss: 0.0576, acc: 0.9714\n",
      "train loss: 0.0725, acc: 0.9790\n",
      "validation loss: 0.0567, acc: 0.9892\n",
      "Epoch 2/6\n",
      "----------\n",
      "phase: train, batch: 500, loss: 0.0026, train_loss: 0.0520, acc: 0.0489\n",
      "phase: train, batch: 1000, loss: 0.0052, train_loss: 0.0538, acc: 0.0977\n",
      "phase: train, batch: 1500, loss: 0.0077, train_loss: 0.0501, acc: 0.1466\n",
      "phase: train, batch: 2000, loss: 0.0103, train_loss: 0.0512, acc: 0.1955\n",
      "phase: train, batch: 2500, loss: 0.0130, train_loss: 0.0541, acc: 0.2443\n",
      "phase: train, batch: 3000, loss: 0.0153, train_loss: 0.0483, acc: 0.2932\n",
      "phase: train, batch: 3500, loss: 0.0178, train_loss: 0.0495, acc: 0.3421\n",
      "phase: train, batch: 4000, loss: 0.0201, train_loss: 0.0471, acc: 0.3910\n",
      "phase: train, batch: 4500, loss: 0.0224, train_loss: 0.0458, acc: 0.4399\n",
      "phase: train, batch: 5000, loss: 0.0247, train_loss: 0.0469, acc: 0.4888\n",
      "phase: train, batch: 5500, loss: 0.0273, train_loss: 0.0507, acc: 0.5377\n",
      "phase: train, batch: 6000, loss: 0.0296, train_loss: 0.0477, acc: 0.5866\n",
      "phase: train, batch: 6500, loss: 0.0319, train_loss: 0.0453, acc: 0.6356\n",
      "phase: train, batch: 7000, loss: 0.0341, train_loss: 0.0450, acc: 0.6845\n",
      "phase: train, batch: 7500, loss: 0.0365, train_loss: 0.0482, acc: 0.7334\n",
      "phase: train, batch: 8000, loss: 0.0387, train_loss: 0.0443, acc: 0.7824\n",
      "phase: train, batch: 8500, loss: 0.0410, train_loss: 0.0461, acc: 0.8313\n",
      "phase: train, batch: 9000, loss: 0.0432, train_loss: 0.0442, acc: 0.8803\n",
      "phase: train, batch: 9500, loss: 0.0453, train_loss: 0.0424, acc: 0.9293\n",
      "phase: train, batch: 10000, loss: 0.0473, train_loss: 0.0419, acc: 0.9783\n",
      "train loss: 0.0476, acc: 0.9860\n",
      "validation loss: 0.0533, acc: 0.9898\n",
      "Epoch 3/6\n",
      "----------\n",
      "phase: train, batch: 500, loss: 0.0022, train_loss: 0.0446, acc: 0.0490\n",
      "phase: train, batch: 1000, loss: 0.0042, train_loss: 0.0395, acc: 0.0980\n",
      "phase: train, batch: 1500, loss: 0.0063, train_loss: 0.0424, acc: 0.1470\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#decrease lr and train more \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "model = train_model(model, criterion, optimizer, num_epochs=6)\n",
    "evaluate(model, criterion, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'model.pre-trained_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluate(model, criterion, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_image_np(inp):\n",
    "    \"\"\"Convert a Tensor to numpy image.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    mean = np.array([0.5])\n",
    "    std = np.array([0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "def visualize_stn():\n",
    "    with torch.no_grad():\n",
    "        data = next(iter(dataloaders['train']))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_tensor = model.stn(data).cpu()\n",
    "\n",
    "        input_grid = convert_image_np(make_grid(input_tensor))\n",
    "        transformed_grid = convert_image_np(make_grid(transformed_tensor))\n",
    "\n",
    "        # Plot the results side-by-side\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        fig.set_size_inches((16, 16))\n",
    "        ax[0].imshow(input_grid)\n",
    "        ax[0].set_title('Dataset Images')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(transformed_grid)\n",
    "        ax[1].set_title('Transformed Images')\n",
    "        ax[1].axis('off')\n",
    "        \n",
    "visualize_stn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#unfreeze the whole model and train for two more epochs\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = True \n",
    "#model = train_model(model, criterion, optimizer, num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save and load the model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.resnet50(pretrained=False).to(device)\n",
    "#model.fc = nn.Sequential(\n",
    "#               nn.Linear(2048, 128),\n",
    "#               nn.ReLU(inplace=True),\n",
    "#               nn.Linear(128, 2)).to(device)\n",
    "#model.load_state_dict(torch.load('weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.resnet18(pretrained=False).to(device)\n",
    "#model.fc = nn.Linear(512, 43).to(device)\n",
    "#model.load_state_dict(torch.load('weights.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Make predictions on sample test images¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_img_paths = [\"./source_data_2/test/00/00243.ppm\",\n",
    "                        \"./source_data_2/test/01/00001.ppm\",\n",
    "                        \"./source_data_2/test/02/00034.ppm\"]\n",
    "#validation_img_paths = [\"./source_data_2/train/35/hflip_hflip_00039_00010.ppm\",\n",
    "#                        \"./source_data_2/train/35/hflip_hflip_00039_00021.ppm\",\n",
    "#                        \"./source_data_2/train/35/hflip_hflip_00039_00029.ppm\"]\n",
    "img_list = [Image.open(img_path) for img_path in validation_img_paths]\n",
    "validation_classes = [0, 1, 2]\n",
    "#validation_classes = [35, 35, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_batch = torch.stack([data_transform(img).to(device)\n",
    "                                for img in img_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits_tensor = model(validation_batch)\n",
    "pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_probs=np.random.random_sample((3, 43))\n",
    "\n",
    "fig, axs = plt.subplots(1, len(img_list), figsize=(10, 3))\n",
    "for i, img in enumerate(img_list):\n",
    "    ax = axs[i]\n",
    "    ax.axis('off')\n",
    "    maxConfidenceValue = np.amax(pred_probs[i,:])\n",
    "    maxConfidenceClass = np.where(pred_probs[i,:] == maxConfidenceValue)[0][0]\n",
    "    color = 'green'\n",
    "    if maxConfidenceClass != validation_classes[i]:\n",
    "        color = 'red'\n",
    "    ax.set_title(\"GT: {}, Top: {} ({:.2f}%)\".format(validation_classes[i], maxConfidenceClass, maxConfidenceValue*100), color=color)\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDT = datetime.datetime.now()\n",
    "print (str(currentDT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
