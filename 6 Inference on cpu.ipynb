{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Inference on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-04 16:38:29.906753\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "currentDT = datetime.datetime.now()\n",
    "print (str(currentDT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create PyTorch data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def to_device(x, y):\n",
    "    return x.to(device), y.to(device, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloader parameters\n",
    "batch_size = 64\n",
    "num_workers_test = 4\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "normalize = transforms.Normalize(mean=[0.5],\n",
    "                                 std=[0.5])\n",
    "\n",
    "data_transform_test = transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.Grayscale(1),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder('./source_data_2/test/', data_transform_test)\n",
    "c = torch.utils.data.DataLoader(test_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False, num_workers=num_workers_test)\n",
    "test_dataloader =WrappedDataLoader(c, to_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Stn, self).__init__()\n",
    "        # Spatial transformer localization-network\n",
    "        self.loc_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 50, 7),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(50, 100, 5),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(100 * 4 * 4, 100),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(100, 3 * 2)\n",
    "        )\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xs = self.loc_net(x)\n",
    "        xs = xs.view(-1, 100 * 4 * 4)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self, gray=False):\n",
    "        super(BaselineNet, self).__init__()\n",
    "        #input_chan = 1 if gray else 3\n",
    "        self.stn = Stn()\n",
    "        self.conv1 = nn.Conv2d(1, 100, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(100)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(100, 150, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(250)\n",
    "        self.fc1 = nn.Linear(250 * 3 * 3, 350)\n",
    "        self.fc1_bn = nn.BatchNorm1d(350)\n",
    "        self.fc2 = nn.Linear(350, 43)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stn(x)\n",
    "        x = self.pool(F.elu(self.conv1(x)))\n",
    "        x = self.dropout(self.conv1_bn(x))\n",
    "        x = self.pool(F.elu(self.conv2(x)))\n",
    "        x = self.dropout(self.conv2_bn(x))\n",
    "        x = self.pool(F.elu(self.conv3(x)))\n",
    "        x = self.dropout(self.conv3_bn(x))\n",
    "        x = x.view(-1, 250 * 3 * 3)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.dropout(self.fc1_bn(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = BaselineNet(gray=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaselineNet(\n",
      "  (stn): Stn(\n",
      "    (loc_net): Sequential(\n",
      "      (0): Conv2d(1, 50, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): Conv2d(50, 100, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): ELU(alpha=1.0)\n",
      "    )\n",
      "    (fc_loc): Sequential(\n",
      "      (0): Linear(in_features=1600, out_features=100, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=100, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1): Conv2d(1, 100, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(100, 150, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2_bn): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(150, 250, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv3_bn): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=2250, out_features=350, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(350, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=350, out_features=43, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a0baec80b66c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.pre-trained_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pre-trained_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, x, y, opt=None):\n",
    "    loss = loss_func(model(x), y)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_batch(model, loss_func, x, y):\n",
    "    output = model(x)\n",
    "    loss = loss_func(output, y)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    correct = pred == y.view(*pred.shape)\n",
    "    \n",
    "    return loss.item(), torch.sum(correct).item(), len(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_func, dl):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses, corrects, nums = zip(*[valid_batch(model, loss_func, x, y) for x, y in dl])\n",
    "        test_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        test_accuracy = np.sum(corrects) / np.sum(nums) * 100\n",
    "        \n",
    "    print(f\"Test loss: {test_loss:.6f}\\t\"\n",
    "          f\"Test accruacy: {test_accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2764: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: train, batch: 500, loss: 0.1393, train_loss: 2.8079, acc: 0.0142\n",
      "phase: train, batch: 1000, loss: 0.1921, train_loss: 1.0635, acc: 0.0492\n",
      "phase: train, batch: 1500, loss: 0.2274, train_loss: 0.7123, acc: 0.0891\n",
      "phase: train, batch: 2000, loss: 0.2544, train_loss: 0.5434, acc: 0.1311\n",
      "phase: train, batch: 2500, loss: 0.2764, train_loss: 0.4446, acc: 0.1745\n",
      "phase: train, batch: 3000, loss: 0.2970, train_loss: 0.4142, acc: 0.2182\n",
      "phase: train, batch: 3500, loss: 0.3181, train_loss: 0.4249, acc: 0.2619\n",
      "phase: train, batch: 4000, loss: 0.3368, train_loss: 0.3778, acc: 0.3061\n",
      "phase: train, batch: 4500, loss: 0.3551, train_loss: 0.3699, acc: 0.3506\n",
      "phase: train, batch: 5000, loss: 0.3726, train_loss: 0.3527, acc: 0.3952\n",
      "phase: train, batch: 5500, loss: 0.3900, train_loss: 0.3489, acc: 0.4398\n",
      "phase: train, batch: 6000, loss: 0.4070, train_loss: 0.3438, acc: 0.4845\n",
      "phase: train, batch: 6500, loss: 0.4242, train_loss: 0.3470, acc: 0.5292\n",
      "phase: train, batch: 7000, loss: 0.4381, train_loss: 0.2803, acc: 0.5748\n",
      "phase: train, batch: 7500, loss: 0.4551, train_loss: 0.3423, acc: 0.6195\n",
      "phase: train, batch: 8000, loss: 0.4692, train_loss: 0.2845, acc: 0.6649\n",
      "phase: train, batch: 8500, loss: 0.4840, train_loss: 0.2981, acc: 0.7102\n",
      "phase: train, batch: 9000, loss: 0.5003, train_loss: 0.3291, acc: 0.7551\n",
      "phase: train, batch: 9500, loss: 0.5174, train_loss: 0.3444, acc: 0.7998\n",
      "phase: train, batch: 10000, loss: 0.5341, train_loss: 0.3363, acc: 0.8445\n",
      "train loss: 0.5361, acc: 0.8517\n",
      "validation loss: 0.1236, acc: 0.9674\n",
      "Test loss: 0.090452\tTest accruacy: 97.435%\n",
      "CPU times: user 3min 51s, sys: 32.5 s, total: 4min 23s\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "evaluate(model, criterion, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Make predictions on sample test images¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_img_paths = [\"./source_data_2/test/00/00243.ppm\",\n",
    "                        \"./source_data_2/test/01/00001.ppm\",\n",
    "                        \"./source_data_2/test/02/00034.ppm\"]\n",
    "img_list = [Image.open(img_path) for img_path in validation_img_paths]\n",
    "validation_classes = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_batch = torch.stack([data_transform(img).to(device)\n",
    "                                for img in img_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits_tensor = model(validation_batch)\n",
    "pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(img_list), figsize=(10, 3))\n",
    "for i, img in enumerate(img_list):\n",
    "    ax = axs[i]\n",
    "    ax.axis('off')\n",
    "    maxConfidenceValue = np.amax(pred_probs[i,:])\n",
    "    maxConfidenceClass = np.where(pred_probs[i,:] == maxConfidenceValue)[0][0]\n",
    "    color = 'green'\n",
    "    if maxConfidenceClass != validation_classes[i]:\n",
    "        color = 'red'\n",
    "    ax.set_title(\"GT: {}, Top: {} ({:.2f}%)\".format(validation_classes[i], maxConfidenceClass, maxConfidenceValue*100), color=color)\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDT = datetime.datetime.now()\n",
    "print (str(currentDT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
